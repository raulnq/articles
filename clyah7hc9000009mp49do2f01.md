---
title: "Scaling Kubernetes Pods Based on a Cron Schedule with KEDA"
datePublished: Sat Jul 06 2024 18:46:49 GMT+0000 (Coordinated Universal Time)
cuid: clyah7hc9000009mp49do2f01
slug: scaling-kubernetes-pods-based-on-a-cron-schedule-with-keda
cover: https://cdn.hashnode.com/res/hashnode/image/upload/v1720234440478/cdff43e7-8f76-4fd1-a26c-a9b2610a2437.png
tags: kubernetes, autoscaling, keda

---

So far, we have extensively covered KEDA and its ability to scale Kubernetes pods using various metrics:

* [Horizontal Pod Autoscaling with Kubernetes Event-Driven Autoscaler (KEDA)](https://blog.raulnq.com/horizontal-pod-autoscaling-with-kubernetes-event-driven-autoscaler-keda)
    
* [Scaling Amazon Elastic Kubernetes Service Workloads with KEDA and Amazon CloudWatch](https://blog.raulnq.com/scaling-amazon-elastic-kubernetes-service-workloads-with-keda-and-amazon-cloudwatch)
    
* [Scaling Amazon Elastic Kubernetes Service Workloads with KEDA and SQS](https://blog.raulnq.com/scaling-amazon-elastic-kubernetes-service-workloads-with-keda-and-sqs)
    
* [Scaling Amazon Elastic Kubernetes Service Workloads with KEDA, OTEL Collector, and Amazon CloudWatch](https://blog.raulnq.com/scaling-amazon-elastic-kubernetes-service-workloads-with-keda-otel-collector-and-amazon-cloudwatch)
    
* [Scaling Kubernetes Pods Based on HTTP Traffic using KEDA HTTP Add-on](https://blog.raulnq.com/scaling-kubernetes-pods-based-on-http-traffic-using-keda-http-add-on)
    

Today, we will explore the [**Cron**](https://keda.sh/docs/2.14/scalers/cron/) scaler, which can be combined with the previously mentioned methods to enhance our scaling strategies.

Here's the scenario: we already have autoscaling based on metrics like requests or messages in our applications. Every morning, we quickly reach our regular workload due to normal business operations. With the current setup, achieving the ideal number of pods can take time, and during this period, users might experience some delays in the applications.

One solution could be to increase the minimum number of pods in our setup. However, this would mean maintaining that number even during off-business hours. The other option is to keep a different minimum number of pods during business hours, and this effect can be achieved using an additional trigger in our `ScaledObject` definition:

```yaml
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: myconsumer-scaler
spec:
  scaleTargetRef:
    name: myconsumer-deployment
  minReplicaCount: 1
  maxReplicaCount: 10
  triggers:
  - type: azure-servicebus
    metadata:
      queueName: MyQueue
      queueLength: '10'
    authenticationRef:
      name: myconsumer-trigger-authentication
  - type: cron
    metadata:
      timezone: America/Bogota
      start: 0 8 * * *
      end: 0 20 * * *
      desiredReplicas: "5"
```

When we have multiple triggers for the same scaler, KEDA will start scaling once one trigger meets the criteria. It calculates metrics for each scaler and uses the highest desired replica count to scale the workload. In the given example, from 8 am to 8 pm, the cron trigger ensures a minimum of 5 pods. If the workload demands more pods, the initial trigger can scale up to 10. This approach not only enhances user experience by reducing latency but also helps in managing operational costs effectively. Thank you, and happy coding.